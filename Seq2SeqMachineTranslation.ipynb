{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63080e0a-1840-4e4f-96d6-ef98e7655001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:15:17.670755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 21:15:17.899989: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-18 21:15:17.900015: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-18 21:15:17.958705: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-18 21:15:19.008151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-18 21:15:19.008286: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-18 21:15:19.008301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ali/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randint \n",
    "from numpy import array,argmax\n",
    "from math import ceil,log10,sqrt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed, RepeatVector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5107e71e-ac11-4627-966b-59dcf4a56523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_num_pairs(n_examples, n_numbers, largest):\n",
    "    X,y = [], []\n",
    "    for i in range(n_examples):\n",
    "        in_pattern = [randint(1, largest) for _ in range(n_numbers)]\n",
    "        out_pattern = np.sum(in_pattern)\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677fd92e-94b8-4532-b13d-314304054df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 192], [203, 61], [20, 114], [189, 168], [13, 167], [210, 86], [120, 24], [227, 284], [99, 218], [296, 172]]\n",
      "[221, 264, 134, 357, 180, 296, 144, 511, 317, 468]\n"
     ]
    }
   ],
   "source": [
    "X,y = random_num_pairs(10,2,300)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f4d0d4-8cb0-42a2-91b8-516644cafe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_to_string(X,y, n_numbers, largest):\n",
    "    max_length = n_numbers* ceil(log10(largest+1))+n_numbers -1\n",
    "    Xstr= []\n",
    "    for p in X:\n",
    "        strp = '+'.join([str(n) for n in p])        \n",
    "        strp = ''.join([' ' for _ in range(max_length - len(strp))])+ strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = ceil(log10(n_numbers * (largest+1)))\n",
    "    ystr= []\n",
    "    for p in y:\n",
    "        strp = str(p)\n",
    "        strp = ''.join([' ' for _ in range(max_length - len(strp))])+ strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712b3b8-9cb8-4bd0-85f7-11180345f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstr,ystr =pairs_to_string(X,y, 2,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a27547-dee1-408a-af0d-830577212462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 29+192', ' 203+61', ' 20+114', '189+168', ' 13+167', ' 210+86', ' 120+24', '227+284', ' 99+218', '296+172'] ['221', '264', '134', '357', '180', '296', '144', '511', '317', '468']\n"
     ]
    }
   ],
   "source": [
    "print(Xstr,ystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb8d2b2-d1d5-411f-9ffa-e35acbf723a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode(X, y, alphsbets):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphsbets))\n",
    "    Xenc = []\n",
    "    for p in X:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        Xenc.append(integer_encoded)\n",
    "    yenc = []\n",
    "    for p in y:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fed328a-cc69-4f82-a43c-77bff5f1d79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[10, 1, 8, 11, 0, 8, 1],\n",
       "  [10, 1, 9, 2, 11, 5, 0],\n",
       "  [10, 1, 9, 11, 0, 0, 3],\n",
       "  [0, 7, 8, 11, 0, 5, 7],\n",
       "  [10, 0, 2, 11, 0, 5, 6],\n",
       "  [10, 1, 0, 9, 11, 7, 5],\n",
       "  [10, 0, 1, 9, 11, 1, 3],\n",
       "  [1, 1, 6, 11, 1, 7, 3],\n",
       "  [10, 8, 8, 11, 1, 0, 7],\n",
       "  [1, 8, 5, 11, 0, 6, 1]],\n",
       " [[1, 1, 0],\n",
       "  [1, 5, 3],\n",
       "  [0, 2, 3],\n",
       "  [2, 4, 6],\n",
       "  [0, 7, 9],\n",
       "  [1, 8, 5],\n",
       "  [0, 3, 3],\n",
       "  [4, 0, 0],\n",
       "  [2, 0, 6],\n",
       "  [3, 5, 7]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_encode(Xstr,ystr,['1','2','3','4','5','6','7','8','9','0',' ','+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a7df4d-be15-4119-9ad7-bdb68ce96bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = []\n",
    "    for p in X:\n",
    "        pattern = []\n",
    "        for index in p:\n",
    "            Vector = [0 for _ in range(max_int)]\n",
    "            Vector[index] = 1\n",
    "            pattern.append(Vector)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = []\n",
    "    for p in y:\n",
    "        pattern = []\n",
    "        for index in p:\n",
    "            Vector = [0 for _ in range(max_int)]\n",
    "            Vector[index] = 1\n",
    "            pattern.append(Vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5afbe8-f6a9-40d5-a6c0-a53201e3a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_decode(seq, alphsbets):\n",
    "    int_to_char = dict((i,c) for i, c in enumerate(alphsbets))\n",
    "    strings =[]\n",
    "    for p in seq:\n",
    "        string = int_to_char[argmax(p)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c048c828-a16e-4609-8f95-f6422171cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, n_numbers, largest, alphsbets):\n",
    "    X,y = random_num_pairs(n_samples, n_numbers, largest)\n",
    "    Xstr,ystr =pairs_to_string(X,y, n_numbers, largest)\n",
    "    Xenc, yenc = integer_encode(Xstr,ystr,alphsbets)\n",
    "    X,y = one_hot_encode(Xenc, yenc,len(alphsbets))\n",
    "    X,y =np.array(X),np.array(y)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c50ef1c-270c-4f31-b92e-77869b8816d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "n_samples =10000\n",
    "n_numbers = 3\n",
    "largest = 20\n",
    "alphsbets=['1','2','3','4','5','6','7','8','9','0',' ','+']\n",
    "n_chars = len(alphsbets)\n",
    "n_in_seq_length = n_numbers* ceil(log10(largest+1))+n_numbers -1\n",
    "n_out_seq_length =  ceil(log10(n_numbers *(largest+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "176e7d00-b92e-4e42-bd21-6db2b46a20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_data(n_samples, n_numbers, largest, alphsbets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825fe467-0907-4b73-b862-8219b5746734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63c150c-d829-426c-a3e4-b5e67b21084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1be606-72e0-4a50-ab6a-627ea2eb4266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6731104a-8183-4f78-960e-bbb556586fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:15:21.991089: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-03-18 21:15:21.991156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: momeni\n",
      "2023-03-18 21:15:21.991183: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: momeni\n",
      "2023-03-18 21:15:21.991380: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2023-03-18 21:15:21.991454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.108.3\n",
      "2023-03-18 21:15:21.991477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.108.3\n",
      "2023-03-18 21:15:21.991985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_in_seq_length,n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ddfcaa-7153-42c7-a132-b6bb00fcbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2444abd2-98c8-4e7e-b50f-426c546686b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 2, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 2, 64)             49408     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 2, 12)            780       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,380\n",
      "Trainable params: 122,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b585ca6b-1f11-4edf-9724-107348a92a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = generate_data(int(n_samples/20), n_numbers, largest, alphsbets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee7d21d-5544-4ea5-8eed-16d65ebccac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 9s 21ms/step - loss: 1.9194 - accuracy: 0.2774 - val_loss: 1.6103 - val_accuracy: 0.3770\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 1.5363 - accuracy: 0.3938 - val_loss: 1.4544 - val_accuracy: 0.4310\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 1.4241 - accuracy: 0.4394 - val_loss: 1.3702 - val_accuracy: 0.4580\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.3540 - accuracy: 0.4760 - val_loss: 1.3008 - val_accuracy: 0.5160\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.3088 - accuracy: 0.5005 - val_loss: 1.2501 - val_accuracy: 0.5360\n",
      "epoch:  1\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.2445 - accuracy: 0.5391 - val_loss: 1.1715 - val_accuracy: 0.5950\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.1573 - accuracy: 0.5687 - val_loss: 1.1042 - val_accuracy: 0.5840\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.0184 - accuracy: 0.6304 - val_loss: 0.9317 - val_accuracy: 0.6390\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.8771 - accuracy: 0.6978 - val_loss: 0.8242 - val_accuracy: 0.6730\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.7592 - accuracy: 0.7474 - val_loss: 0.6727 - val_accuracy: 0.8290\n",
      "epoch:  2\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6358 - accuracy: 0.8263 - val_loss: 0.5604 - val_accuracy: 0.8580\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.5606 - accuracy: 0.8544 - val_loss: 0.5071 - val_accuracy: 0.8720\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.4892 - accuracy: 0.8888 - val_loss: 0.4304 - val_accuracy: 0.9400\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.4251 - accuracy: 0.9240 - val_loss: 0.4150 - val_accuracy: 0.9190\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.3787 - accuracy: 0.9388 - val_loss: 0.3541 - val_accuracy: 0.9520\n",
      "epoch:  3\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.3248 - accuracy: 0.9679 - val_loss: 0.3060 - val_accuracy: 0.9710\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.3397 - accuracy: 0.9216 - val_loss: 0.2689 - val_accuracy: 0.9890\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2783 - accuracy: 0.9589 - val_loss: 0.2614 - val_accuracy: 0.9720\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2356 - accuracy: 0.9768 - val_loss: 0.2302 - val_accuracy: 0.9770\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1997 - accuracy: 0.9840 - val_loss: 0.1754 - val_accuracy: 0.9920\n",
      "epoch:  4\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1796 - accuracy: 0.9855 - val_loss: 0.1725 - val_accuracy: 0.9810\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.2585 - accuracy: 0.9232 - val_loss: 0.1467 - val_accuracy: 0.9910\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1376 - accuracy: 0.9918 - val_loss: 0.1255 - val_accuracy: 0.9920\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1851 - accuracy: 0.9545 - val_loss: 0.1347 - val_accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1140 - accuracy: 0.9915 - val_loss: 0.0993 - val_accuracy: 0.9950\n",
      "epoch:  5\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0967 - accuracy: 0.9948 - val_loss: 0.0935 - val_accuracy: 0.9950\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0863 - accuracy: 0.9956 - val_loss: 0.0770 - val_accuracy: 0.9970\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1631 - accuracy: 0.9530 - val_loss: 0.3407 - val_accuracy: 0.8530\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1521 - accuracy: 0.9564 - val_loss: 0.0684 - val_accuracy: 0.9970\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0657 - accuracy: 0.9967 - val_loss: 0.0597 - val_accuracy: 0.9970\n",
      "epoch:  6\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0623 - accuracy: 0.9961 - val_loss: 0.0534 - val_accuracy: 0.9960\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.2180 - accuracy: 0.9294 - val_loss: 0.1002 - val_accuracy: 0.9890\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0627 - accuracy: 0.9954 - val_loss: 0.0488 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0501 - accuracy: 0.9969 - val_loss: 0.0440 - val_accuracy: 0.9970\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0445 - accuracy: 0.9972 - val_loss: 0.0404 - val_accuracy: 0.9980\n",
      "epoch:  7\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0846 - accuracy: 0.9808 - val_loss: 0.4620 - val_accuracy: 0.8170\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1903 - accuracy: 0.9281 - val_loss: 0.1689 - val_accuracy: 0.9340\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0703 - accuracy: 0.9845 - val_loss: 0.0366 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0357 - accuracy: 0.9972 - val_loss: 0.0330 - val_accuracy: 0.9970\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0328 - accuracy: 0.9977 - val_loss: 0.0304 - val_accuracy: 0.9980\n",
      "epoch:  8\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0326 - accuracy: 0.9973 - val_loss: 0.0304 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0299 - accuracy: 0.9977 - val_loss: 0.0278 - val_accuracy: 0.9970\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0273 - accuracy: 0.9974 - val_loss: 0.0254 - val_accuracy: 0.9960\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0581 - accuracy: 0.9860 - val_loss: 0.4023 - val_accuracy: 0.8490\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1916 - accuracy: 0.9424 - val_loss: 0.0360 - val_accuracy: 0.9970\n",
      "epoch:  9\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0278 - accuracy: 0.9969 - val_loss: 0.0247 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1065 - accuracy: 0.9681 - val_loss: 0.1900 - val_accuracy: 0.9270\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1267 - accuracy: 0.9580 - val_loss: 0.0240 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: 0.0217 - val_accuracy: 0.9960\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0217 - accuracy: 0.9978 - val_loss: 0.0206 - val_accuracy: 0.9970\n",
      "epoch:  10\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0203 - accuracy: 0.9979 - val_loss: 0.0182 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0184 - accuracy: 0.9984 - val_loss: 0.0169 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0174 - accuracy: 0.9987 - val_loss: 0.0156 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0167 - accuracy: 0.9989 - val_loss: 0.0176 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.0169 - val_accuracy: 0.9980\n",
      "epoch:  11\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.3412 - accuracy: 0.9074 - val_loss: 0.0353 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0271 - accuracy: 0.9982 - val_loss: 0.0197 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0195 - accuracy: 0.9986 - val_loss: 0.0160 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0164 - accuracy: 0.9989 - val_loss: 0.0142 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 0.0130 - val_accuracy: 0.9990\n",
      "epoch:  12\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1976 - accuracy: 0.9376 - val_loss: 0.0489 - val_accuracy: 0.9960\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0329 - accuracy: 0.9946 - val_loss: 0.0159 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0180 - accuracy: 0.9983 - val_loss: 0.0199 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0147 - accuracy: 0.9985 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0129 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9990\n",
      "epoch:  13\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 0.0106 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0110 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 0.0110 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2440 - accuracy: 0.9349 - val_loss: 0.0761 - val_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0222 - accuracy: 0.9982 - val_loss: 0.0138 - val_accuracy: 0.9990\n",
      "epoch:  14\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0147 - accuracy: 0.9989 - val_loss: 0.0114 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 0.0105 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2309 - accuracy: 0.9298 - val_loss: 0.0221 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.0141 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0122 - accuracy: 0.9994 - val_loss: 0.0117 - val_accuracy: 0.9990\n",
      "epoch:  15\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0100 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
      "epoch:  16\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.2948 - accuracy: 0.9226 - val_loss: 0.0247 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0187 - accuracy: 0.9985 - val_loss: 0.0186 - val_accuracy: 0.9970\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1695 - accuracy: 0.9406 - val_loss: 0.0346 - val_accuracy: 0.9970\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0144 - accuracy: 0.9990 - val_loss: 0.0119 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.0108 - val_accuracy: 0.9990\n",
      "epoch:  17\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0083 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "epoch:  18\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.0073 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.2745 - accuracy: 0.9191 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 0.0268 - val_accuracy: 0.9950\n",
      "epoch:  19\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1658 - accuracy: 0.9434 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "epoch:  20\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0958 - accuracy: 0.9855 - val_loss: 1.4395 - val_accuracy: 0.6500\n",
      "epoch:  21\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.4968 - accuracy: 0.8548 - val_loss: 0.0996 - val_accuracy: 0.9690\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.0519 - val_accuracy: 0.9880\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0348 - accuracy: 0.9930 - val_loss: 0.0283 - val_accuracy: 0.9960\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0868 - accuracy: 0.9741 - val_loss: 0.0272 - val_accuracy: 0.9960\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0206 - accuracy: 0.9972 - val_loss: 0.0198 - val_accuracy: 0.9980\n",
      "epoch:  22\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0185 - accuracy: 0.9973 - val_loss: 0.0180 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.1220 - val_accuracy: 0.9510\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0993 - accuracy: 0.9672 - val_loss: 0.0180 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0154 - accuracy: 0.9984 - val_loss: 0.0160 - val_accuracy: 0.9980\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.0148 - val_accuracy: 0.9970\n",
      "epoch:  23\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.0129 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.0121 - val_accuracy: 0.9980\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1179 - accuracy: 0.9732 - val_loss: 0.3392 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.0145 - val_accuracy: 0.9980\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.0123 - val_accuracy: 0.9980\n",
      "epoch:  24\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.0116 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0116 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1159 - accuracy: 0.9646 - val_loss: 0.0154 - val_accuracy: 0.9990\n",
      "epoch:  25\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0107 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1461 - accuracy: 0.9512 - val_loss: 0.0763 - val_accuracy: 0.9760\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0182 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 0.9980\n",
      "epoch:  26\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9990\n",
      "epoch:  27\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1648 - accuracy: 0.9499 - val_loss: 0.0518 - val_accuracy: 0.9940\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0088 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "epoch:  28\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1150 - accuracy: 0.9633 - val_loss: 0.1612 - val_accuracy: 0.9370\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
      "epoch:  29\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "epoch:  30\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.2560 - accuracy: 0.9554 - val_loss: 0.7500 - val_accuracy: 0.7290\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.1436 - accuracy: 0.9549 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "epoch:  31\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "epoch:  32\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0887 - accuracy: 0.9818 - val_loss: 1.3110 - val_accuracy: 0.7340\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.1046 - accuracy: 0.9718 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "epoch:  33\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 1.6971 - val_accuracy: 0.7460\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2265 - accuracy: 0.9416 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "epoch:  34\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "epoch:  35\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.2912 - accuracy: 0.9262 - val_loss: 0.0395 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0172 - accuracy: 0.9989 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "epoch:  36\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "epoch:  37\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.2027 - accuracy: 0.9471 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "epoch:  38\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.4543 - accuracy: 0.8990 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0137 - accuracy: 0.9995 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "epoch:  39\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "epoch:  40\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1777 - accuracy: 0.9538 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0118 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "epoch:  41\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "epoch:  42\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.2251 - accuracy: 0.9545 - val_loss: 0.1179 - val_accuracy: 0.9690\n",
      "epoch:  43\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0229 - accuracy: 0.9971 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "epoch:  44\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "epoch:  45\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.3080 - accuracy: 0.9298 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "epoch:  46\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "epoch:  47\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "epoch:  48\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.1582 - accuracy: 0.9599 - val_loss: 0.0496 - val_accuracy: 0.9890\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "epoch:  49\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    X,y = generate_data(n_samples, n_numbers, largest, alphsbets)\n",
    "    print('epoch: ',i)\n",
    "    model.fit(X,y, epochs=5,validation_data=(X_test,y_test), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af4c14-0963-4f8c-8b05-f2a0066dafba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d7617e7-3b56-47ec-8f90-3ad0e8a3e6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b15d33c9-3b57-4d1b-9fd9-370401287468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_decode(result[0],alphsbets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98cf210-d305-46c4-a06e-5d92e8623085",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('37', '37'),\n",
       " ('38', '38'),\n",
       " (' 8', ' 8'),\n",
       " ('33', '33'),\n",
       " ('40', '40'),\n",
       " ('35', '35'),\n",
       " ('36', '36'),\n",
       " ('38', '38'),\n",
       " ('35', '35'),\n",
       " ('33', '33'),\n",
       " ('25', '25'),\n",
       " ('18', '18'),\n",
       " ('47', '47'),\n",
       " ('33', '33'),\n",
       " ('24', '24'),\n",
       " ('26', '26'),\n",
       " ('32', '32'),\n",
       " (' 8', ' 8'),\n",
       " ('13', '13'),\n",
       " ('50', '50'),\n",
       " ('33', '33'),\n",
       " ('44', '44'),\n",
       " ('40', '40'),\n",
       " ('31', '31'),\n",
       " ('40', '40'),\n",
       " ('39', '39'),\n",
       " ('22', '22'),\n",
       " ('39', '39'),\n",
       " ('13', '13'),\n",
       " ('34', '34'),\n",
       " ('20', '20'),\n",
       " ('26', '26'),\n",
       " ('34', '34'),\n",
       " ('32', '32'),\n",
       " ('38', '38'),\n",
       " ('37', '37'),\n",
       " ('35', '35'),\n",
       " ('42', '42'),\n",
       " ('31', '31'),\n",
       " ('34', '34'),\n",
       " ('36', '36'),\n",
       " ('16', '16'),\n",
       " ('28', '28'),\n",
       " ('34', '34'),\n",
       " ('37', '37'),\n",
       " ('23', '23'),\n",
       " ('39', '39'),\n",
       " ('30', '30'),\n",
       " ('23', '23'),\n",
       " ('23', '23'),\n",
       " ('32', '32'),\n",
       " ('35', '35'),\n",
       " ('21', '21'),\n",
       " ('24', '24'),\n",
       " ('19', '19'),\n",
       " ('32', '32'),\n",
       " ('15', '15'),\n",
       " ('27', '27'),\n",
       " ('34', '34'),\n",
       " ('44', '44'),\n",
       " ('36', '36'),\n",
       " ('38', '38'),\n",
       " ('33', '33'),\n",
       " ('30', '30'),\n",
       " ('21', '21'),\n",
       " ('16', '16'),\n",
       " ('30', '30'),\n",
       " ('27', '27'),\n",
       " ('27', '27'),\n",
       " ('28', '28'),\n",
       " ('33', '33'),\n",
       " ('24', '24'),\n",
       " ('22', '22'),\n",
       " ('45', '45'),\n",
       " ('48', '48'),\n",
       " ('36', '36'),\n",
       " ('39', '39'),\n",
       " ('28', '28'),\n",
       " ('17', '17'),\n",
       " ('30', '30'),\n",
       " ('41', '41'),\n",
       " ('33', '33'),\n",
       " ('41', '41'),\n",
       " ('34', '34'),\n",
       " ('20', '20'),\n",
       " ('41', '41'),\n",
       " ('50', '50'),\n",
       " ('31', '31'),\n",
       " ('47', '47'),\n",
       " ('32', '32'),\n",
       " ('40', '40'),\n",
       " ('37', '37'),\n",
       " ('20', '20'),\n",
       " ('31', '31'),\n",
       " (' 7', ' 7'),\n",
       " ('42', '42'),\n",
       " ('26', '26'),\n",
       " ('36', '36'),\n",
       " ('15', '15'),\n",
       " ('34', '34'),\n",
       " ('36', '36'),\n",
       " ('15', '15'),\n",
       " ('41', '41'),\n",
       " ('33', '33'),\n",
       " ('16', '16'),\n",
       " ('35', '35'),\n",
       " ('26', '26'),\n",
       " ('28', '28'),\n",
       " ('55', '55'),\n",
       " ('26', '26'),\n",
       " ('46', '46'),\n",
       " ('34', '34'),\n",
       " ('23', '23'),\n",
       " ('29', '29'),\n",
       " ('29', '29'),\n",
       " ('25', '25'),\n",
       " ('26', '26'),\n",
       " ('29', '29'),\n",
       " ('24', '24'),\n",
       " ('31', '31'),\n",
       " ('30', '30'),\n",
       " ('35', '35'),\n",
       " ('13', '13'),\n",
       " ('32', '32'),\n",
       " ('44', '44'),\n",
       " ('36', '36'),\n",
       " ('30', '30'),\n",
       " ('27', '27'),\n",
       " ('31', '31'),\n",
       " ('28', '28'),\n",
       " ('26', '26'),\n",
       " ('54', '54'),\n",
       " ('29', '29'),\n",
       " ('19', '19'),\n",
       " ('16', '16'),\n",
       " ('38', '38'),\n",
       " ('22', '22'),\n",
       " ('24', '24'),\n",
       " ('31', '31'),\n",
       " ('26', '26'),\n",
       " ('16', '16'),\n",
       " ('23', '23'),\n",
       " ('37', '37'),\n",
       " ('33', '33'),\n",
       " ('28', '28'),\n",
       " ('24', '24'),\n",
       " ('10', '10'),\n",
       " ('39', '39'),\n",
       " ('23', '23'),\n",
       " ('37', '37'),\n",
       " ('20', '20'),\n",
       " ('32', '32'),\n",
       " ('29', '29'),\n",
       " ('35', '35'),\n",
       " ('37', '37'),\n",
       " ('44', '44'),\n",
       " ('40', '40'),\n",
       " ('23', '23'),\n",
       " ('43', '43'),\n",
       " ('34', '34'),\n",
       " ('35', '35'),\n",
       " ('32', '32'),\n",
       " ('55', '55'),\n",
       " ('34', '34'),\n",
       " ('26', '26'),\n",
       " ('17', '17'),\n",
       " ('25', '25'),\n",
       " ('21', '21'),\n",
       " ('23', '23'),\n",
       " ('23', '23'),\n",
       " ('34', '34'),\n",
       " ('45', '45'),\n",
       " ('23', '23'),\n",
       " ('34', '34'),\n",
       " ('35', '35'),\n",
       " ('23', '23'),\n",
       " ('37', '37'),\n",
       " ('28', '28'),\n",
       " ('19', '19'),\n",
       " ('35', '35'),\n",
       " ('40', '40'),\n",
       " ('26', '26'),\n",
       " ('25', '25'),\n",
       " ('19', '19'),\n",
       " ('32', '32'),\n",
       " ('12', '12'),\n",
       " ('48', '48'),\n",
       " ('35', '35'),\n",
       " ('43', '43'),\n",
       " ('37', '37'),\n",
       " ('37', '37'),\n",
       " ('40', '40'),\n",
       " ('22', '22'),\n",
       " ('31', '31'),\n",
       " ('17', '17'),\n",
       " ('17', '17'),\n",
       " ('39', '39'),\n",
       " ('18', '18'),\n",
       " ('23', '23'),\n",
       " ('25', '25'),\n",
       " ('30', '30'),\n",
       " ('31', '31'),\n",
       " ('25', '25'),\n",
       " ('42', '42'),\n",
       " ('46', '46'),\n",
       " ('34', '34'),\n",
       " ('36', '36'),\n",
       " ('33', '33'),\n",
       " ('23', '23'),\n",
       " ('14', '14'),\n",
       " ('30', '30'),\n",
       " ('34', '34'),\n",
       " ('15', '15'),\n",
       " ('29', '29'),\n",
       " ('29', '29'),\n",
       " ('46', '46'),\n",
       " ('46', '46'),\n",
       " ('43', '43'),\n",
       " ('29', '29'),\n",
       " ('17', '17'),\n",
       " ('32', '32'),\n",
       " ('33', '33'),\n",
       " ('37', '37'),\n",
       " ('33', '33'),\n",
       " ('42', '42'),\n",
       " ('34', '34'),\n",
       " ('52', '52'),\n",
       " ('26', '26'),\n",
       " ('32', '32'),\n",
       " ('22', '22'),\n",
       " ('35', '35'),\n",
       " ('32', '32'),\n",
       " ('36', '36'),\n",
       " ('17', '17'),\n",
       " ('20', '20'),\n",
       " ('21', '21'),\n",
       " ('41', '41'),\n",
       " (' 9', ' 9'),\n",
       " (' 5', ' 5'),\n",
       " ('31', '31'),\n",
       " ('36', '36'),\n",
       " ('28', '28'),\n",
       " ('17', '17'),\n",
       " ('23', '23'),\n",
       " ('24', '24'),\n",
       " ('36', '36'),\n",
       " ('35', '35'),\n",
       " ('33', '33'),\n",
       " ('42', '42'),\n",
       " ('35', '35'),\n",
       " ('30', '30'),\n",
       " ('15', '15'),\n",
       " ('47', '47'),\n",
       " ('50', '50'),\n",
       " ('29', '29'),\n",
       " ('31', '31'),\n",
       " ('25', '25'),\n",
       " ('33', '33'),\n",
       " ('37', '37'),\n",
       " ('28', '28'),\n",
       " ('39', '39'),\n",
       " ('23', '23'),\n",
       " ('42', '42'),\n",
       " ('22', '22'),\n",
       " ('27', '27'),\n",
       " ('34', '34'),\n",
       " ('41', '41'),\n",
       " ('19', '19'),\n",
       " ('26', '26'),\n",
       " ('34', '34'),\n",
       " ('24', '24'),\n",
       " ('32', '32'),\n",
       " ('33', '33'),\n",
       " ('20', '20'),\n",
       " ('21', '21'),\n",
       " ('25', '25'),\n",
       " ('51', '51'),\n",
       " ('16', '16'),\n",
       " ('31', '31'),\n",
       " ('30', '30'),\n",
       " ('19', '19'),\n",
       " ('32', '32'),\n",
       " ('41', '41'),\n",
       " ('36', '36'),\n",
       " ('35', '35'),\n",
       " ('26', '26'),\n",
       " ('25', '25'),\n",
       " ('28', '28'),\n",
       " ('38', '38'),\n",
       " ('32', '32'),\n",
       " ('47', '47'),\n",
       " ('33', '33'),\n",
       " ('14', '14'),\n",
       " ('21', '21'),\n",
       " ('23', '23'),\n",
       " ('31', '31'),\n",
       " ('49', '49'),\n",
       " ('41', '41'),\n",
       " ('45', '45'),\n",
       " ('38', '38'),\n",
       " ('45', '45'),\n",
       " ('28', '28'),\n",
       " ('20', '20'),\n",
       " ('26', '26'),\n",
       " ('37', '37'),\n",
       " ('46', '46'),\n",
       " ('48', '48'),\n",
       " ('17', '17'),\n",
       " ('34', '34'),\n",
       " ('14', '14'),\n",
       " ('26', '26'),\n",
       " ('45', '45'),\n",
       " ('35', '35'),\n",
       " ('48', '48'),\n",
       " ('51', '51'),\n",
       " ('28', '28'),\n",
       " ('32', '32'),\n",
       " ('33', '33'),\n",
       " ('32', '32'),\n",
       " ('34', '34'),\n",
       " ('36', '36'),\n",
       " ('42', '42'),\n",
       " ('45', '45'),\n",
       " ('40', '40'),\n",
       " ('29', '29'),\n",
       " ('28', '28'),\n",
       " ('30', '30'),\n",
       " ('36', '36'),\n",
       " ('24', '24'),\n",
       " ('26', '26'),\n",
       " ('35', '35'),\n",
       " ('47', '47'),\n",
       " ('37', '37'),\n",
       " ('23', '23'),\n",
       " ('15', '15'),\n",
       " ('34', '34'),\n",
       " ('39', '39'),\n",
       " ('32', '32'),\n",
       " ('53', '53'),\n",
       " ('38', '38'),\n",
       " ('28', '28'),\n",
       " ('37', '37'),\n",
       " ('29', '29'),\n",
       " ('32', '32'),\n",
       " ('53', '53'),\n",
       " ('54', '54'),\n",
       " ('17', '17'),\n",
       " ('38', '38'),\n",
       " ('40', '40'),\n",
       " ('19', '19'),\n",
       " ('39', '39'),\n",
       " ('31', '31'),\n",
       " (' 8', ' 8'),\n",
       " ('39', '39'),\n",
       " ('42', '42'),\n",
       " ('32', '32'),\n",
       " ('26', '26'),\n",
       " ('27', '27'),\n",
       " ('34', '34'),\n",
       " ('25', '25'),\n",
       " ('27', '27'),\n",
       " ('31', '31'),\n",
       " ('32', '32'),\n",
       " ('40', '40'),\n",
       " ('29', '29'),\n",
       " ('39', '39'),\n",
       " ('20', '20'),\n",
       " ('33', '33'),\n",
       " ('46', '46'),\n",
       " ('40', '40'),\n",
       " ('39', '39'),\n",
       " ('27', '27'),\n",
       " ('23', '23'),\n",
       " ('38', '38'),\n",
       " ('45', '45'),\n",
       " ('27', '27'),\n",
       " ('16', '16'),\n",
       " ('28', '28'),\n",
       " ('10', '10'),\n",
       " ('57', '57'),\n",
       " ('35', '35'),\n",
       " ('36', '36'),\n",
       " ('37', '37'),\n",
       " ('33', '33'),\n",
       " ('33', '33'),\n",
       " ('26', '26'),\n",
       " ('24', '24'),\n",
       " ('29', '29'),\n",
       " ('37', '37'),\n",
       " ('36', '36'),\n",
       " ('35', '35'),\n",
       " ('26', '26'),\n",
       " ('46', '46'),\n",
       " ('30', '30'),\n",
       " ('29', '29'),\n",
       " ('40', '40'),\n",
       " ('33', '33'),\n",
       " ('33', '33'),\n",
       " ('30', '30'),\n",
       " ('21', '21'),\n",
       " ('24', '24'),\n",
       " ('34', '34'),\n",
       " ('28', '28'),\n",
       " ('25', '25'),\n",
       " ('17', '17'),\n",
       " ('42', '42'),\n",
       " ('29', '29'),\n",
       " ('46', '46'),\n",
       " ('33', '33'),\n",
       " ('37', '37'),\n",
       " ('25', '25'),\n",
       " ('31', '31'),\n",
       " ('29', '29'),\n",
       " ('33', '33'),\n",
       " ('43', '43'),\n",
       " ('23', '23'),\n",
       " ('52', '52'),\n",
       " ('25', '25'),\n",
       " ('16', '16'),\n",
       " ('20', '20'),\n",
       " ('46', '46'),\n",
       " ('25', '25'),\n",
       " ('19', '19'),\n",
       " ('13', '13'),\n",
       " ('45', '45'),\n",
       " ('42', '42'),\n",
       " ('44', '44'),\n",
       " ('31', '31'),\n",
       " ('36', '36'),\n",
       " ('28', '28'),\n",
       " ('34', '34'),\n",
       " ('36', '36'),\n",
       " ('16', '16'),\n",
       " ('24', '24'),\n",
       " ('20', '20'),\n",
       " ('15', '15'),\n",
       " ('41', '41'),\n",
       " ('22', '22'),\n",
       " ('29', '29'),\n",
       " ('30', '30'),\n",
       " ('37', '37'),\n",
       " ('19', '19'),\n",
       " (' 9', ' 9'),\n",
       " ('25', '25'),\n",
       " ('21', '21'),\n",
       " ('23', '23'),\n",
       " ('34', '34'),\n",
       " ('48', '48'),\n",
       " ('28', '28'),\n",
       " ('25', '25'),\n",
       " ('43', '43'),\n",
       " ('35', '35'),\n",
       " ('20', '20'),\n",
       " ('52', '52'),\n",
       " ('21', '21'),\n",
       " ('43', '43'),\n",
       " ('11', '11'),\n",
       " ('23', '23'),\n",
       " ('38', '38'),\n",
       " ('29', '29'),\n",
       " ('13', '13'),\n",
       " ('31', '31'),\n",
       " ('11', '11'),\n",
       " ('33', '33'),\n",
       " ('40', '40'),\n",
       " ('42', '42'),\n",
       " ('38', '38'),\n",
       " ('27', '27'),\n",
       " ('39', '39'),\n",
       " ('30', '30'),\n",
       " ('59', '59'),\n",
       " ('35', '35'),\n",
       " ('29', '29'),\n",
       " ('32', '32'),\n",
       " ('42', '42'),\n",
       " ('30', '30'),\n",
       " ('38', '38'),\n",
       " ('28', '28'),\n",
       " ('32', '32'),\n",
       " ('30', '30'),\n",
       " ('43', '43'),\n",
       " ('41', '41'),\n",
       " ('29', '29'),\n",
       " ('33', '33'),\n",
       " ('40', '40'),\n",
       " ('36', '36'),\n",
       " ('22', '22'),\n",
       " ('36', '36'),\n",
       " ('30', '30'),\n",
       " ('33', '33'),\n",
       " ('33', '33'),\n",
       " ('31', '31'),\n",
       " ('39', '39'),\n",
       " ('23', '23'),\n",
       " ('36', '36'),\n",
       " ('27', '27'),\n",
       " ('12', '12'),\n",
       " ('21', '21'),\n",
       " ('16', '16'),\n",
       " ('18', '18')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = [integer_decode(y1, alphsbets) for y1 in y_test]\n",
    "pred = [integer_decode(y1, alphsbets) for y1 in result]\n",
    "list(zip(exp, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bd4d7a7-a57e-4440-ae76-7ebec1fe0975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.abs((np.array(exp,dtype='int') - np.array(pred,dtype='int')).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
